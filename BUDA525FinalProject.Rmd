---
title: " BUDA 525 Final Project"
author: "Jordan, Ethan, Valentina, Namita"
output: word_document
---


## 3a) Load data and quick scan

```{r load, echo=TRUE, message=FALSE, warning=FALSE}
library(ISLR)
library(car)
library(effects)
data("Credit")
str(Credit)
summary(Credit)
```

**Takeaway:**  
The data set has 400 records and 12 columns describing people’s credit information. A few numeric variables like Income, Limit, and Balance vary a lot and lean heavily to the right, meaning some people have much larger values than most others. The sample is split fairly evenly between men and women, and most observations are non-students.

## 3b) Categorical comparisons

```{r cats, echo=FALSE, fig.height=4, fig.width=7}
par(mfrow=c(2,2), mar=c(4,4,2,1))
boxplot(Balance~Student,  data=Credit, main="Balance by Student")
boxplot(Balance~Ethnicity,data=Credit, main="Balance by Ethnicity")
boxplot(Balance~Married,  data=Credit, main="Balance by Married")
boxplot(Balance~Gender,   data=Credit, main="Balance by Gender")
par(mfrow=c(1,1))
```

**Takeaway:**  
Students tend to carry higher average balances, which fits the idea that people with lower or unstable income rely more on credit. The differences across Ethnicity, Married, and Gender are small, so they probably won’t help prediction and could introduce bias. We’ll focus on more meaningful numeric and behavioral factors instead.

## 3c) Balance distribution

```{r dist, echo=FALSE, fig.height=3.8, fig.width=7}
par(mfrow=c(2,1), mar=c(4,4,2,1))
hist(Credit$Balance, main="Distribution of Credit Balances", col="lightblue")
plot(Credit$Balance, ylab="Balance", main="Balances by Observation")
par(mfrow=c(1,1))
```

**Takeaway:**  
The balance variable is very skewed many customers have a zero balance while a few have extremely high ones. This pattern can make it hard for a linear model to behave well, so we may need transformations or we might drop the zeros later to see if the model improves.

## 3d) Full model and diagnostics

```{r fullmods, echo=TRUE, fig.height=4.8, fig.width=7}
mod_full <- lm(Balance ~ Income + Limit + Rating + Cards + Age + Education + Student + Married + Ethnicity + Gender, data=Credit)
summary(mod_full)
par(mfrow=c(2,2), mar=c(4,4,2,1))
plot(mod_full)
par(mfrow=c(1,1))
```

**Takeaway:**  
Residual plots show clear curves and uneven spread, which means the plain linear model doesn’t capture the relationships correctly. A simple linear fit on raw balances isn’t appropriate yet.

## 3e) Small positive offset + stepwise

```{r step, echo=TRUE}
Credit$adj_balance <- Credit$Balance + 1
mod1      <- lm(adj_balance ~ Income + Limit + Rating + Cards + Age + Education + Student + Married + Ethnicity + Gender, data=Credit)
mod1_step <- step(mod1, trace=0)
summary(mod1_step)
```

**Takeaway:**  
Backward AIC removes the weak or redundant predictors (Ethnicity, Education, Married, and Gender). The main drivers that remain are Income, Rating, Limit, Cards, Age, and Student. Lets use that result and implement them into the next model.

## 3f) Transformation guidance

```{r trans, echo=TRUE, fig.height=3.5, fig.width=6.5}
mod2 <- lm(adj_balance ~ Income + Rating + Limit + Cards + Age + Student, data=Credit)
boxCox(mod2)
summary(powerTransform(cbind(Credit$adj_balance, Credit$Income, Credit$Rating, Credit$Limit, Credit$Cards, Credit$Age)))
```

**Takeaway:**  
The Box-Cox test suggests that taking the square root of Balance would help stabilize the variance. The powerTransform results also hint that several predictors might benefit from square-root scaling. We’ll test those adjustments next to see if the model looks cleaner.

## 3g) Transformed model on full data

```{r mod3, echo=TRUE, fig.height=4.8, fig.width=7}
mod3 <- lm(sqrt(adj_balance) ~ sqrt(Income) + sqrt(Rating) + sqrt(Limit) + sqrt(Cards) + Age + Student, data=Credit)
summary(mod3)
par(mfrow=c(2,2), mar=c(4,4,2,1)); plot(mod3); par(mfrow=c(1,1))
```

**Takeaway:**  
The transformations make the residuals look smoother and more even, but there’s still a thin band of points near zero—probably caused by all the zero balances still in the data. That tells us it’s time to try removing them.

## 3h) Remove zero balances and refit

```{r clean, echo=TRUE}
Credit$Balance[Credit$Balance == 0] <- NA
Credit_clean <- na.omit(Credit)  # 310 rows remain
nrow(Credit_clean)
```

```{r mod4, echo=TRUE, fig.height=4.8, fig.width=7}
mod4 <- lm(Balance ~ Income + Rating + Limit + Cards + Age + Student, data=Credit_clean)
summary(mod4)
par(mfrow=c(2,2), mar=c(4,4,2,1)); plot(mod4); par(mfrow=c(1,1))
```

**Takeaway:**  
After removing accounts with zero balances, the residual plots look much better—no clear pattern, nearly normal errors, and no strong outliers. The model now behaves the way we want, so this version becomes our main candidate.

## 3i) Optional checks on clean data

```{r bxpt, echo=TRUE, fig.height=3.4, fig.width=6.5}
boxCox(mod4)
# Use the cleaned data (no NAs) to avoid transformation errors
summary(powerTransform(cbind(Credit_clean$Balance, Credit_clean$Income, Credit_clean$Rating, Credit_clean$Limit, Credit_clean$Cards, Credit_clean$Age)))
```

```{r mod5, echo=TRUE, fig.height=4.8, fig.width=7}
mod5 <- lm(Balance ~ sqrt(Income) + sqrt(Rating) + sqrt(Limit) + sqrt(Cards) + Age + Student, data=Credit_clean)
summary(mod5)
par(mfrow=c(2,2), mar=c(4,4,2,1)); plot(mod5); par(mfrow=c(1,1))
```

**Takeaway:**  
Box-Cox no longer recommends any change to the response once zeros are gone. Forcing square-root transforms on predictors adds a bit of curvature again, so the simpler untransformed model fits better and is easier to interpret.

## 3j) 5-fold cross-validation: transformed vs clean

```{r cv, echo=TRUE}
set.seed(123)
Credit_clean$fold_id <- sample(rep(1:5, length.out = nrow(Credit_clean)))
RSS3 <- 0
RSS4 <- 0
for(k in 1:5){
  test  <- which(Credit_clean$fold_id == k)
  train <- setdiff(1:nrow(Credit_clean), test)
  m3_cv <- lm(sqrt(adj_balance) ~ sqrt(Income) + sqrt(Rating) + sqrt(Limit) + sqrt(Cards) + Age + Student, data=Credit_clean[train,])
  m4_cv <- lm(Balance ~ Income + Rating + Limit + Cards + Age + Student, data=Credit_clean[train,])
  p3 <- predict(m3_cv, newdata=Credit_clean[test,])^2
  p4 <- predict(m4_cv, newdata=Credit_clean[test,])
  RSS3 <- RSS3 + sum((Credit_clean$adj_balance[test] - p3)^2)
  RSS4 <- RSS4 + sum((Credit_clean$Balance[test] - p4)^2)
}
RSS3
RSS4
```

**Takeaway:**  
When we test both models with cross-validation, model4 that is using only positive balances performs much beter. Removing zeros produces more stable and accurate predictions than trying to adjust them mathematically by adding 1 to the balance variable.

## 2k) Effect plots for the best model

```{r effects, echo=FALSE}
plot(allEffects(mod4))
```

**Takeaway:**  
Balances go up when people have higher credit limits or more credit cards, and they’re typically higher for students. Balances go down for people with higher incomes, better credit ratings, and older age. These trends make sense and match real-world behavior.

## 2L) Conclusions

**Takeaway:**  
Our final model, Balance ~ Income + Rating + Limit + Cards + Age + Student explains credit balances well for people who actually carry a balance. It avoids weak or sensitive variables like Gender and Ethnicity and keeps interpretation simple. In practice, this model would be useful for identifying which customers are likely to have larger outstanding balances and why, without over-complicating the analysis.

---

## Question 4

```{r q4, echo=TRUE, message=FALSE, warning=FALSE}
library(carData)
head(Salaries)

tapply(Salaries$salary,Salaries$sex,mean)
t.test(Salaries$salary[Salaries$sex=="Male"], Salaries$salary[Salaries$sex=="Female"], alternative="greater")

all_factors <- lm(salary~sex+discipline+rank+yrs.service+yrs.since.phd,data=Salaries)

no_sex <- lm(salary~.-sex,data=Salaries)
anova(all_factors,no_sex)

no_discipline <- lm(salary~.-discipline,data=Salaries)
anova(all_factors,no_discipline)

no_rank <- lm(salary~.-rank,data=Salaries)
anova(all_factors,no_rank)

no_yrs.service <- lm(salary~.-yrs.service,data=Salaries)
anova(all_factors,no_yrs.service)

no_yrs.since.phd <- lm(salary~.-yrs.since.phd,data=Salaries)
anova(all_factors,no_yrs.since.phd)

table(Salaries$rank,Salaries$sex)
table(Salaries$discipline,Salaries$sex)
```

**Comments:**  
- Using the two sample t-test, the p-value of 0.001332 is below the 0.05 level, so we will reject the null hypothesis. Basing judgement on just gender, men make more than females.  
- **Influences of different factors:**  
  - Sex: 0.2158 > 0.05 : NOT Significant  
  - Discipline: 0.000000001878 < 0.05 : VERY Significant  
  - Rank: 0.00000000000000022 < 0.05 : VERY Significant  
  - Years of Service: 0.02143 < 0.05 : Significant  
  - Years since Phd: 0.02698 < 0.05 : Significant  
- The raw data leads us to believe there is a large gender gap, consisting of men making roughly 14,088 more than women. After taking other factors into consideration and adjusting as needed, we see that rank and discipline are the two leading factors for salary, with years of service and years since phd following. The reasoning for the superstition of men making more than women is because there are more men in higher rank positions and disciplines. We are shown the significance of each factor above, and the tables shows how the sample of men used outranks the women, and the disciplines of each.  
- I don't think this is suitable to make salary offers because although it contains all of the surface variables, it leaves out things such as location, performance, grants, etc. In conclusion, the data is beneficial to sort through and make inferences from, but not meant to make offers from.
